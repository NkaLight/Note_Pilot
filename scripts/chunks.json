[
  "COSC343/AIML402\nMODULE: MACHINE LEARNING\nLECTURE 10: LEARNING\nLech Szymanski\nSchool of Computing, University of Otago S2 2025\nHand-built vs. learning agent\nTwo different approaches to building an AI agent.\n•Designing the whole agent by hand\n•Designing an AI agent which can learn from the sensory data it receives\nCOSC343/AIML402 L10: Learning 2\nThe agent function\nPercepts/Input to Actions/Output\nP 7→ A\ny=f(x)x1∈ {0\nA,1\nB}\nx2∈ {0\nClean,1\nDirty}\ny1∈ {−1\nLeft,0\nNo-op,1\nRight}\ny2∈ {0\nNo-op,1\nSuck}",
  "P 7→ A\ny=f(x)x1∈ {0\nA,1\nB}\nx2∈ {0\nClean,1\nDirty}\ny1∈ {−1\nLeft,0\nNo-op,1\nRight}\ny2∈ {0\nNo-op,1\nSuck}\nP A\nRoom sensor Dirty sensor Drive control Suck control\n0 0 1 0\n0 1 0 1\n1 0 -1 0\n1 1 0 1\nCOSC343/AIML402 L10: Learning 3\nThe agent function as a hypothesis\nTrue function,\ny=f(x)\nis unknown.\nSo, we make ahypothesis\nfunction\nˆy=h(x,w)\n(Hypothesis will often be referred\nto as themodel)xi∈ {0, . . . ,255}\ny1∈ {0\nNo face,1\nFace}\nx y\nx1 x8256 y1\n73 . . . 22 1\n161 . . . 30 0\n22 . . . 14 0",
  "y1∈ {0\nNo face,1\nFace}\nx y\nx1 x8256 y1\n73 . . . 22 1\n161 . . . 30 0\n22 . . . 14 0\n211 . . . 126 1\nCOSC343/AIML402 L10: Learning 4\nSupervised learning\nInsupervised learning, the agent learns a function from inputs to outputs:\n•A sample of labelled data (i.e. inputs and corresponding outputs of the\n“supposed” true agent function) for a given task is given.\n•A parameterised model mapping inputs to outputs is chosen.\n•The learning algorithm works out the parameter values of the model that produce",
  "•The learning algorithm works out the parameter values of the model that produce\nthe “correct” output for given input.\nCOSC343/AIML402 L10: Learning 5\nSupervised learning example\nGiven a set of labelled images learn the how to classify them.\nCOSC343/AIML402 L10: Learning 6\nUnsupervised learning\nInunsupervised learning, the learning algorithm receives a set of training data, and\nhas to work out what regularities it contains:",
  "has to work out what regularities it contains:\n•A sample of unlabelled data is given (i.e. examples of inputs, but not target\noutputs).\n•A parameterised model is chosen.\n•The learning algorithm works out the the parameter values of the model that\n“organises”/”categorises” data according to some chosen criteria.\nCOSC343/AIML402 L10: Learning 7\nUnsupervised learning example\nSay we have a set of data, where there is a lot of redundant information; unsupervised",
  "Say we have a set of data, where there is a lot of redundant information; unsupervised\nalgorithm can spot the most relevant and common patterns to retain as the\ncompressed representation.\nCOSC343/AIML402 L10: Learning 8\nReinforcement learning\nInreinforcement learning, the agent receives data and generates actions in response:\n•An agent is placed in an environment, which provides a reinforcement signal, a\npositive or negative reward depending on the effects of agent’s actions",
  "positive or negative reward depending on the effects of agent’s actions\n•A parameterised model mapping percepts to actions is chosen.\n•The agent generates sequences of actions recording their effects through percepts\nand any received reward(s).\n•The learning algorithm works out the the parameter values of the model that\ngenerate actions that maximise the rewards for a given situation (inferred from\nthe percepts).\nCOSC343/AIML402 L10: Learning 9\nReinforcement learning example",
  "the percepts).\nCOSC343/AIML402 L10: Learning 9\nReinforcement learning example\nAn agent learning how to play chess needs to perform a sequence of actions (chess\nmoves) in order to bring the game to a close and then, depending whether it won or\nlost, receives a positive or negative rewards, from which it needs to deduce ‘good’ and\n’bad’ actions.\nCOSC343/AIML402 L10: Learning 10\nClassification vs. regression tasks",
  "’bad’ actions.\nCOSC343/AIML402 L10: Learning 10\nClassification vs. regression tasks\nFrom the modelling point of view, there are two important distinctions of the learning\ntasks:\n•classification– those where the model outputs a discrete value from a finite set\nof choices (related to decision making)\nFor example: Given images of two faces – are the individuals related or not?\n•regression– those that involve the model to output a continuous (real number)\nvalue (related to approximation)",
  "value (related to approximation)\nFor example: Given images of two faces – what is the genetic distance between\ntwo individuals?\nCOSC343/AIML402 L10: Learning 11\nPerformance metric\nIn machine learning, we evaluate the performance of a model with ametric, which\ngives:\n•the average “distance” of the model’s output from the target value, suchmean\nsquared error(typically used in regression)\n•the fraction of the model outputs that are wrong (don’t match the target",
  "•the fraction of the model outputs that are wrong (don’t match the target\noutputs) referred to as theclassification error(typically used in classification)\n•Sometimes expressed asaccuracy, the fraction of examples labelled correctly.\naccuracy= 1−classification error\nCOSC343/AIML402 L10: Learning 12\nConfusion matrix\nOverall accuracy/classification error often hides vital information on the distribution of\nthe errors between classes. Aconfusion matrixprovides more information based on",
  "the errors between classes. Aconfusion matrixprovides more information based on\ngrouping of actual labels and the predicted labels. For example, inbinary\nclassification, where one class can be thought aspositivesand the other asnegatives,\nthe confusion matrix shows the counts of true/false positives/negatives, from which\nvarious measurements can be derived:\nTrue positives (TP) False negatives (FN)\nFalse positives (FP) True negatives (TN)",
  "True positives (TP) False negatives (FN)\nFalse positives (FP) True negatives (TN)\nTotal number of positives (labels of one type) in the data is TP+FN.\nTotal number of negatives (labels of second type) in the data is FP+TN.\nTotal number of positive predictions by the model is TP+FP.\nTotal number of negative predictions by the model is FN+TN.\nCOSC343/AIML402 L10: Learning 13\nSupervised learning: induction\nThe basic principle behind supervised learning isinduction. We can define an",
  "The basic principle behind supervised learning isinduction. We can define an\ninductive learning procedure as follows:\n•Assume there is some “true”, unknown function,fwhich takes input and returns\n”true” outputy=f(x)\n•An indirect evidence of the “true” function is data sample of pairs(x,y)\n•Inductive learning process:\n1. Create a hypothesis function ˆy=h(x,w)with random statew\n2. Compute ˆy=h(x,w)for currentw\n3. If ˆynot close toy, modifywand go back to step 2.\n•Hopefullyh(x,w)≈f(x)",
  "3. If ˆynot close toy, modifywand go back to step 2.\n•Hopefullyh(x,w)≈f(x)\nWe want a hypothesis function whichgeneraliseswell to unseen examples off.\nCOSC343/AIML402 L10: Learning 14\nGeneralisation\n“All generalisations are false, including this one.”\nMark Twain\n“Essentially, all models are wrong, but some are useful.”\nGeorge Box\nUseful models are the one that perform well on unseen data, i.e.they generalise\nCOSC343/AIML402 L10: Learning 15\nConsistency and simplicity",
  "COSC343/AIML402 L10: Learning 15\nConsistency and simplicity\nAconsistenthypothesis*is one which agrees with all the training examples.\n•It is possible for a consistent model to not perform well on new (previously unseen)\ndata – such model is said to have beenovertrained, and itoverfitsthe data.\nThere are typically many consistent hypotheses for a given training set. How to choose\nbetween them?\n•Occam’s razortells us to prefer the simplest hypothesis. Simpler solutions tend",
  "between them?\n•Occam’s razortells us to prefer the simplest hypothesis. Simpler solutions tend\nto generalise better to new examples.\nThere is typically a trade off between consistency and simplicity:\n•We can often get a much simpler hypothesis if we’re allowed to ignore a few\ntraining examples.\n*Don’t confuse with consistent heuristic.\nCOSC343/AIML402 L10: Learning 16\nExample: Generalisation and curve-fitting\nQuestion: What’s the function?\nxf(x)\nCOSC343/AIML402 L10: Learning 17\nNoise",
  "Question: What’s the function?\nxf(x)\nCOSC343/AIML402 L10: Learning 17\nNoise\nIt would be nice if the training data was perfect...\n...but in the real world nothing is perfect - observations are noisy and labels might be\ninaccurate.\nMachine learning algorithms must make useful inferences in the imperfect world.\nCOSC343/AIML402 L10: Learning 18\nTraining and testing\n•Data available for training is usually split in two sets\n•Training– data used to train the model",
  "•Data available for training is usually split in two sets\n•Training– data used to train the model\n•Testing– data used to verify the performance of the model\n•Consistency, good performance on training data, is not necessarily an indication of\ngood generalisation – your hypothesis might be overfitting the data.\n•Good performance on test data is a better indicator of generalisation... but only\nas good as your test set.\nCOSC343/AIML402 L10: Learning 19\nLab 5: Spam filtering\nObjectives:",
  "as good as your test set.\nCOSC343/AIML402 L10: Learning 19\nLab 5: Spam filtering\nObjectives:\n•To review the concepts from Bayesian reasoning\n•To implement a Naive Bayes’ Classifier\n•To apply the Naive Bayes’ Classifier to the problem of spam filtering\n•To get into the habit of training and testing machine learning models on\nseparated train and test sets\nCOSC343/AIML402 L10: Learning 20\nStudy guide\n•Understand how input/output table relates to a function\n•What is a parameterised hypothesis?",
  "•Understand how input/output table relates to a function\n•What is a parameterised hypothesis?\n•Know the three types of learning feedback (and be able to give examples):\nsupervised, unsupervised and reinforcement learning.\n•Understand the inductive supervised learning process.\n•Terms and definitions: hypothesis consistency, generalisation, overtraining,\noverfitting, Occam’s razor, discriminative vs. generative models, classification vs.",
  "overfitting, Occam’s razor, discriminative vs. generative models, classification vs.\nregression, loss function, classification error/accuracy, confusion matrix.\n•Understand the need for separating training and test sets.\nReading for this lecture What’s next?\nAIMA Chapter 18, Sections 1–2 Decision Trees\nRead AIMA Chapter 19, Section 3\nCOSC343/AIML402 L10: Learning 21"
]